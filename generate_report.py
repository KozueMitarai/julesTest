import os
import google.generativeai as genai
from datetime import datetime, timedelta

# 1. APIã‚­ãƒ¼ã®è¨­å®š
api_key = os.environ.get("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚GitHubã®Secretsã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

genai.configure(api_key=api_key)

# 2. ãƒ¢ãƒ‡ãƒ«ã®è¨­å®š (æœ€æ–°ã®Gemini 3 Flash Preview + Googleæ¤œç´¢ãƒ„ãƒ¼ãƒ«)
model = genai.GenerativeModel(
    model_name='gemini-3-flash-preview',
    tools=[{'google_search': {}}] 
)

# 3. æ—¥ä»˜ã®è¨ˆç®—ï¼ˆä»Šæ—¥ã¨7æ—¥å‰ï¼‰
today_dt = datetime.now()
today = today_dt.strftime('%Y-%m-%d')
one_week_ago = (today_dt - timedelta(days=7)).strftime('%Y-%m-%d')

# 4. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ
prompt = f"""
ã‚ãªãŸã¯æœ€æ–°ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã«ç²¾é€šã—ãŸè¦ªã—ã¿ã‚„ã™ã„ITãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
Googleæ¤œç´¢ã‚’ä½¿ç”¨ã—ã¦ã€ä»¥ä¸‹ã®æ¡ä»¶ã§ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€æ¤œç´¢ã®åˆ¶ç´„ã€‘
- æœŸé–“: {one_week_ago} ã‹ã‚‰ {today} ã¾ã§ï¼ˆç›´è¿‘1é€±é–“ä»¥å†…ï¼‰ã®æƒ…å ±ã«é™å®šã—ã¦ãã ã•ã„ã€‚
- æ¤œç´¢æ™‚ã¯å¿…ãš `after:{one_week_ago}` æ¼”ç®—å­ã‚’æ´»ç”¨ã—ã€å¤ã„æƒ…å ±ã‚’é™¤å¤–ã—ã¦ãã ã•ã„ã€‚

ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã€‘
- AIã«èˆˆå‘³ã¯ã‚ã‚‹ãŒã€å°‚é–€ç”¨èªã«ã¯è©³ã—ããªã„ä¸€èˆ¬ã®ãƒ“ã‚¸ãƒã‚¹ãƒ‘ãƒ¼ã‚½ãƒ³ã€‚

ã€ãƒ¬ãƒãƒ¼ãƒˆæ§‹æˆã€‘
1. ä»Šé€±ã®é‡è¦AIãƒ‹ãƒ¥ãƒ¼ã‚¹TOP3ï¼ˆä½•ãŒèµ·ããŸã®ã‹ï¼Ÿï¼‰
2. éã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãŒæ³¨ç›®ã™ã¹ããƒã‚¤ãƒ³ãƒˆï¼ˆãªãœé‡è¦ãªã®ã‹ï¼Ÿï¼‰
3. æ˜æ—¥ã‹ã‚‰ä»•äº‹ã§ä½¿ãˆã‚‹AIæ´»ç”¨ã®ãƒ’ãƒ³ãƒˆï¼ˆå…·ä½“çš„ãªæ´»ç”¨æ³•ï¼‰

ã€åŸ·ç­†ã‚¹ã‚¿ã‚¤ãƒ«ã€‘
- å°‚é–€ç”¨èªã‚’é¿ã‘ã€ä¸­å­¦ç”Ÿã§ã‚‚ç†è§£ã§ãã‚‹è¨€è‘‰ã§è§£èª¬ã—ã¦ãã ã•ã„ã€‚
- èª­è€…ãŒãƒ¯ã‚¯ãƒ¯ã‚¯ã™ã‚‹ã‚ˆã†ãªã€å‰å‘ãã§æ˜ã‚‹ã„ãƒˆãƒ¼ãƒ³ã§åŸ·ç­†ã—ã¦ãã ã•ã„ã€‚
- å‡ºåŠ›ã¯Markdownå½¢å¼ã€‚
- ã‚¿ã‚¤ãƒˆãƒ«ã¯ã€Œã€{today}ç‰ˆã€‘AIã‚’å‘³æ–¹ã«ï¼ä»Šé€±ã®æœ€æ–°æ´»ç”¨ãƒˆãƒ¬ãƒ³ãƒ‰ã€ã¨ã—ã¦ãã ã•ã„ã€‚
"""

try:
    print(f"[{today}] ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã‚’é–‹å§‹ã—ã¾ã™...")
    
    # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ
    response = model.generate_content(prompt)
    content = response.text

    # 5. å¼•ç”¨å…ƒï¼ˆã‚½ãƒ¼ã‚¹ï¼‰æƒ…å ±ã®æŠ½å‡º
    sources = []
    if response.candidates and response.candidates[0].grounding_metadata:
        metadata = response.candidates[0].grounding_metadata
        if hasattr(metadata, 'grounding_chunks'):
            for chunk in metadata.grounding_chunks:
                if chunk.web:
                    title = chunk.web.title if chunk.web.title else "å‚ç…§è¨˜äº‹"
                    uri = chunk.web.uri
                    sources.append(f"- [{title}]({uri})")

    # æœ¬æ–‡ã¨ã‚½ãƒ¼ã‚¹ä¸€è¦§ã‚’çµåˆ
    final_report = content
    if sources:
        unique_sources = "\n".join(list(dict.fromkeys(sources))) # é‡è¤‡æ’é™¤
        final_report += f"\n\n---\n### ğŸ“Š ã“ã®è¨˜äº‹ã®å‚ç…§å…ƒï¼ˆç›´è¿‘1é€±é–“ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼‰\n{unique_sources}"

    # 6. Markdownãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
    output_dir = "reports"
    os.makedirs(output_dir, exist_ok=True)
    filename = f"{output_dir}/ai_report_{today}.md"
    
    with open(filename, "w", encoding="utf-8") as f:
        f.write(final_report)
        
    print(f"æˆåŠŸ: {filename} ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")

except Exception as e:
    print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    exit(1)
